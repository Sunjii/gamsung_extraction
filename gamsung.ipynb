{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "class RE_Dataset(torch.utils.data.Dataset):\n",
    "  \"\"\" Dataset 구성을 위한 class.\"\"\"\n",
    "  def __init__(self, pair_dataset, labels):\n",
    "    self.pair_dataset = pair_dataset\n",
    "    self.labels = labels\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    item = {key: val[idx].clone().detach() for key, val in self.pair_dataset.items()}\n",
    "    item['labels'] = torch.tensor(self.labels[idx])\n",
    "    return item\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "\n",
    "def preprocessing_dataset(dataset):\n",
    "    \"\"\"처음 불러온 csv 파일을 원하는 형태의 DataFrame으로 변경\"\"\"\n",
    "    labels = []\n",
    "    sentences = []\n",
    "    for i,j in zip(dataset['label'], dataset['sentence']):\n",
    "        labels.append(i)\n",
    "        sentences.append(j)\n",
    "    out_dataset = pd.DataFrame({'label':dataset['label'], 'sentence':dataset['sentence']})\n",
    "    return out_dataset\n",
    "\n",
    "def load_data(dataset_dir):\n",
    "    \"\"\"csv 파일을 경로에 맡게 불러 옵니다.\"\"\"\n",
    "    pd_dataset = pd.read_csv(dataset_dir, encoding='cp949')\n",
    "    dataset = preprocessing_dataset(pd_dataset)\n",
    "    return dataset\n",
    "\n",
    "def tokenized_dataset(dataset, tokenizer):\n",
    "  \"\"\" tokenizer에 따라 sentence를 tokenizing 합니다.\"\"\"\n",
    "  concat_entity = []\n",
    "  for s in dataset['sentence']: # 데이터셋의 엔티티 두개를 추출\n",
    "    concat_entity.append(s)\n",
    "  tokenized_sentences = tokenizer(\n",
    "      concat_entity,\n",
    "      #list(dataset['sentence']),\n",
    "      return_tensors=\"pt\",\n",
    "      padding=True,\n",
    "      truncation=True,\n",
    "      max_length=256,\n",
    "      add_special_tokens=True,\n",
    "      )\n",
    "  return tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 5 3 4 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_list = ['분노', '슬픔','불안','상처','당황','기쁨']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(label_list)\n",
    "\n",
    "print(encoder.transform(label_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_num(label):\n",
    "    num_label = encoder.transform(label)\n",
    "    return num_label\n",
    "\n",
    "def num_to_label(label):\n",
    "    origin_label = encoder.inverse_transform(label)\n",
    "    return origin_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "def klue_re_micro_f1(preds, labels):\n",
    "    \"\"\"KLUE-RE micro f1 (except no_relation)\"\"\"\n",
    "    label_list = ['분노', '슬픔','불안','상처','당황','기쁨']\n",
    "    #no_relation_label_idx = label_list.index(\"no_relation\")\n",
    "    label_indices = list(range(len(label_list)))\n",
    "    #label_indices.remove(no_relation_label_idx)\n",
    "    return sklearn.metrics.f1_score(labels, preds, average=\"micro\", labels=label_indices) * 100.0\n",
    "\n",
    "def klue_re_auprc(probs, labels):\n",
    "    \"\"\"KLUE-RE AUPRC (with no_relation)\"\"\"\n",
    "    labels = np.eye(6)[labels]\n",
    "\n",
    "    score = np.zeros((6,))\n",
    "    for c in range(6):\n",
    "        targets_c = labels.take([c], axis=1).ravel()\n",
    "        preds_c = probs.take([c], axis=1).ravel()\n",
    "        precision, recall, _ = sklearn.metrics.precision_recall_curve(\n",
    "            targets_c, preds_c)\n",
    "        score[c] = sklearn.metrics.auc(recall, precision)\n",
    "    return np.average(score) * 100.0\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    \"\"\" validation을 위한 metrics function \"\"\"\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    probs = pred.predictions\n",
    "\n",
    "    # calculate accuracy using sklearn's function\n",
    "    f1 = klue_re_micro_f1(preds, labels)\n",
    "    auprc = klue_re_auprc(probs, labels)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "\n",
    "    return {\n",
    "        'micro f1 score': f1,\n",
    "        'auprc': auprc,\n",
    "        'accuracy': acc,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label                                           sentence\n",
      "0        기쁨                          아내가 드디어 출산하게 되어서 정말 신이 나.\n",
      "1        불안            당뇨랑 합병증 때문에 먹어야 할 약이 열 가지가 넘어가니까 스트레스야.\n",
      "2        당황            고등학교에 올라오니 중학교 때보다 수업이 갑자기 어려워져서 당황스러워.\n",
      "3        기쁨      재취업이 돼서 받게 된 첫 월급으로 온 가족이 외식을 할 예정이야. 너무 행복해.\n",
      "4        기쁨                       빚을 드디어 다 갚게 되어서 이제야 안도감이 들어.\n",
      "...     ...                                                ...\n",
      "40874    불안  같이 사는 친구가 애완견을 데려왔는데 대부분 내가 돌보고 있어. 내가 주인인가 혼란...\n",
      "40875    기쁨                  지난주에 건강검진 결과가 나왔는데 정상이라고 결과가 나왔어.\n",
      "40876    슬픔          엄마는 내 꿈인 작가를 응원해 주고는 했는데 지금은 안 그래. 너무 슬퍼.\n",
      "40877    기쁨            이렇게 좋은 운동 시설에서 경로 우대로 운동할 수 있다니 참 행운이야.\n",
      "40878    불안                친구 관계가 너무 힘들어. 베푸는 만큼 돌아오지 않는 것 같아.\n",
      "\n",
      "[40879 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_data('./dataset.csv')\n",
    "dataset[\"label\"]\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def train():\n",
    "    seed_everything(42)\n",
    "    # load model and tokenizer\n",
    "    MODEL_NAME = 'klue/bert-base'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    # load dataset\n",
    "    dataset = load_data('./dataset.csv')\n",
    "    target = label_to_num(dataset[\"label\"].values)\n",
    "    train_dataset, dev_dataset = train_test_split(\n",
    "        dataset, test_size=0.15, shuffle=True, stratify=target,\n",
    "    )\n",
    "\n",
    "    train_label = label_to_num(train_dataset['label'].values)\n",
    "    dev_label = label_to_num(dev_dataset['label'].values)\n",
    "\n",
    "    # tokenizing dataset\n",
    "    tokenized_train = tokenized_dataset(train_dataset, tokenizer)\n",
    "    tokenized_dev = tokenized_dataset(dev_dataset, tokenizer)\n",
    "\n",
    "    # make dataset for pytorch.\n",
    "    RE_train_dataset = RE_Dataset(tokenized_train, train_label)\n",
    "    RE_dev_dataset = RE_Dataset(tokenized_dev, dev_label)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(device)\n",
    "\n",
    "    # setting model hyperparameter\n",
    "    model_config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "    model_config.num_labels = 6\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME, config=model_config)\n",
    "    print(model.config)\n",
    "    model.parameters\n",
    "    model.to(device)\n",
    "\n",
    "    # 사용한 option 외에도 다양한 option들이 있습니다.\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',          # output directory\n",
    "        save_total_limit=5,              # number of total save model.\n",
    "        save_steps=500,                 # model saving step.\n",
    "        num_train_epochs=10,              # total number of training epochs\n",
    "        learning_rate=1e-4,               # learning_rate\n",
    "        # batch size per device during training\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "        warmup_ratio=0.1,\n",
    "        warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.01,               # strength of weight decay\n",
    "        logging_dir='./logs',            # directory for storing logs\n",
    "        logging_steps=100,              # log saving step.\n",
    "        evaluation_strategy='steps',  # evaluation strategy to adopt during training\n",
    "        # `no`: No evaluation during training.\n",
    "        # `steps`: Evaluate every `eval_steps`.\n",
    "        # `epoch`: Evaluate every end of epoch.\n",
    "        eval_steps=500,            # evaluation step.\n",
    "        metric_for_best_model='eval_micro f1 score',  # eval_micro f1 score\n",
    "        load_best_model_at_end=True,\n",
    "        lr_scheduler_type='cosine',  # default: linear\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        # the instantiated 🤗 Transformers model to be trained\n",
    "        model=model,\n",
    "        args=training_args,                  # training arguments, defined above\n",
    "        train_dataset=RE_train_dataset,         # training dataset\n",
    "        eval_dataset=RE_dev_dataset,             # evaluation dataset\n",
    "        compute_metrics=compute_metrics         # define metrics function\n",
    "    )\n",
    "\n",
    "    # trainer.hyperparameter_search(direction=\"maximize\", hp_space=my_hp_space_ray)\n",
    "    # train model\n",
    "    trainer.train()\n",
    "\n",
    "    model.save_pretrained(f'./best_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda empty cache!!\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"cuda empty cache!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"klue/bert-base\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.5.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='5430' max='5430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5430/5430 1:03:56, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro f1 score</th>\n",
       "      <th>Auprc</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.032300</td>\n",
       "      <td>1.075343</td>\n",
       "      <td>61.692759</td>\n",
       "      <td>68.550034</td>\n",
       "      <td>0.616928</td>\n",
       "      <td>10.289300</td>\n",
       "      <td>595.956000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.937700</td>\n",
       "      <td>1.003533</td>\n",
       "      <td>64.155251</td>\n",
       "      <td>71.447631</td>\n",
       "      <td>0.641553</td>\n",
       "      <td>10.454600</td>\n",
       "      <td>586.536000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.761100</td>\n",
       "      <td>1.050495</td>\n",
       "      <td>64.171559</td>\n",
       "      <td>70.751000</td>\n",
       "      <td>0.641716</td>\n",
       "      <td>10.288800</td>\n",
       "      <td>595.986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.547900</td>\n",
       "      <td>1.149174</td>\n",
       "      <td>65.410959</td>\n",
       "      <td>69.971622</td>\n",
       "      <td>0.654110</td>\n",
       "      <td>10.279100</td>\n",
       "      <td>596.549000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>1.339058</td>\n",
       "      <td>64.856491</td>\n",
       "      <td>69.484260</td>\n",
       "      <td>0.648565</td>\n",
       "      <td>10.282400</td>\n",
       "      <td>596.359000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.212800</td>\n",
       "      <td>1.508211</td>\n",
       "      <td>65.117417</td>\n",
       "      <td>68.712111</td>\n",
       "      <td>0.651174</td>\n",
       "      <td>10.275000</td>\n",
       "      <td>596.789000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.124900</td>\n",
       "      <td>1.749596</td>\n",
       "      <td>65.231572</td>\n",
       "      <td>68.146820</td>\n",
       "      <td>0.652316</td>\n",
       "      <td>10.421700</td>\n",
       "      <td>588.390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>1.938252</td>\n",
       "      <td>64.774951</td>\n",
       "      <td>67.704602</td>\n",
       "      <td>0.647750</td>\n",
       "      <td>11.133000</td>\n",
       "      <td>550.793000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>2.046523</td>\n",
       "      <td>65.362035</td>\n",
       "      <td>67.753900</td>\n",
       "      <td>0.653620</td>\n",
       "      <td>10.334100</td>\n",
       "      <td>593.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>2.097542</td>\n",
       "      <td>65.215264</td>\n",
       "      <td>67.841107</td>\n",
       "      <td>0.652153</td>\n",
       "      <td>11.554000</td>\n",
       "      <td>530.727000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-k개 추론 결과를 보여주자\n",
    "\n",
    "def tokenizing(sentence, tokenizer):\n",
    "    \"\"\" tokenizer에 따라 sentence를 tokenizing 합니다.\"\"\"\n",
    "    tokenized_sentence = tokenizer(\n",
    "        sentence,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        add_special_tokens=True,\n",
    "      )\n",
    "        \n",
    "    return tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'klue/bert-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "a = tokenizing(\"안녕하세요.\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   2, 5891, 2205, 5971,   18,    3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "tensor([[   2, 5891, 2205, 5971,   18,    3]])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(a['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def inference(sentence, model):\n",
    "    model.eval()\n",
    "    MODEL_NAME = 'klue/bert-base'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    \n",
    "    output_pred = []\n",
    "    output_prob = []\n",
    "    \n",
    "    # sentence 토크나이징\n",
    "    tokenized_sent = tokenizing(sentence, tokenizer)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=tokenized_sent['input_ids'].to(device),\n",
    "            attention_mask=tokenized_sent['attention_mask'].to(device),\n",
    "            token_type_ids=tokenized_sent['token_type_ids'].to(device)\n",
    "        )\n",
    "    '''\n",
    "    SequenceClassifierOutput(loss=None, logits=tensor([[ 2.8013,  0.9778, -2.0565,  2.7867, -1.6169, -2.9289]],\n",
    "       device='cuda:0'), hidden_states=None, attentions=None)\n",
    "    '''\n",
    "    \n",
    "    logits = outputs[0]\n",
    "    prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    result = np.argmax(logits, axis=-1)    \n",
    "    \n",
    "    output_pred.append(result)\n",
    "    output_prob.append(prob)\n",
    "  \n",
    "    return np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(sentence):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model = AutoModelForSequenceClassification.from_pretrained('./best_model')\n",
    "    model.to(device)\n",
    "\n",
    "    pred_answer, output_prob = inference(sentence, model)\n",
    "    pred_answer = num_to_label(pred_answer)\n",
    "\n",
    "    print(pred_answer, output_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['기쁨'] [[0.46331310272216797, 0.008690078742802143, 0.05478760227560997, 0.11694328486919403, 0.034610211849212646, 0.32165566086769104]]\n",
      "['불안'] [[0.007257037330418825, 0.002930098446086049, 0.030506860464811325, 0.5612196922302246, 0.022893842309713364, 0.3751924932003021]]\n",
      "['당황'] [[0.0023562866263091564, 0.992356538772583, 0.0004910796997137368, 0.004630960524082184, 9.798115934245288e-05, 6.713408947689459e-05]]\n",
      "['당황'] [[0.00031427424983121455, 0.9889928698539734, 0.009809978306293488, 0.0005756760365329683, 0.00015612594143021852, 0.00015096743300091475]]\n",
      "['분노'] [[0.0005168858915567398, 0.0013337378622964025, 0.7627708911895752, 0.0010220204712823033, 0.2239847034215927, 0.010371852666139603]]\n"
     ]
    }
   ],
   "source": [
    "prediction('누군지 보려고 달려간 공주가 문을 열었을 때 어마나 세상에 문 앞에 어제 그 개구리가 앉아 있지 뭐예요.')\n",
    "prediction('누가 봐도 공주의 얼굴이 붉으락푸르락한 게 보였어요.')\n",
    "prediction('그래서 공주가 문을 사정없이 닫아버리고는 허둥대며 다시 자리로 와 식사를 계속했지만, 공주도 너무나도 놀란 건 사실이었어요.')\n",
    "prediction('딸애야, 왜 그러니? 문 앞에서 너를 데려가려는 거인이라도 본 게냐?')\n",
    "prediction('“아, 아냐,”라며 공주가 말했어요. “거인이 아니라 구역질나는 개구리 한 마리야.”')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['상처'] [[0.0005434234044514596, 0.00031408053473569453, 7.354172703344375e-05, 0.0005094616208225489, 0.9984968900680542, 6.258022040128708e-05]]\n",
      "['기쁨'] [[0.9994732737541199, 8.953684300649911e-05, 0.00020760462211910635, 8.277779852505773e-05, 4.648189860745333e-05, 0.0001003616489470005]]\n",
      "['기쁨'] [[0.9990330934524536, 8.229914237745106e-05, 0.00012298690853640437, 0.0001815058058127761, 7.205220026662573e-05, 0.0005080334958620369]]\n"
     ]
    }
   ],
   "source": [
    "span1 = '거대한 숲에서 아내와 함께 힘들게 살고 있는 나무꾼이 하나 있었습니다. 그들에게는 세 살 배기 어린 딸이 하나 있었습니다. 하지만 그들은 너무도 가난했기 때문에 양식을 구할 길이 없어 딸아이를 어찌 먹여살릴지 앞이 깜깜했습니다.'\n",
    "span2 = '일곱 명의 새끼 염소들이 그 광경을 지켜보다 우물가로 달려와 환호성을 지르며 소리쳤어요. “만세! 늑대가 죽었다! 늑대가 죽었어!” 새끼 염소들은 너무 기뻐서 엄마 염소와 함께 우물가 주변을 둥글게 돌며 춤을 추었답니다.'\n",
    "span3 = '왕은 어쩐지 제비가 두려웠다. 자신처럼 작은 이들에게는 거구의 새처럼 보였다. 하지만 엄지 공주를 보고는 무척 기뻐했다. 소녀는 지금껏 본 가장 아름다운 소녀였다. 그래서 황금 왕관을 벗어 소녀의 머리에 얹고는 이름을 물어도 되냐고 조심스럽게 묻고는 자신의 아내가 되어 달라고 부탁했다. 그러면 소녀는 모든 꽃의 여왕이 될 것이다. 정말이지 두꺼비 아들, 검은 벨벳 코트를 입은 두더지와는 완전히 다른 남편감이었다. 그래서 소녀는 이 매력적인 왕에게 “좋아요”라고 말했다. 꽃 속에서 자그마한 숙녀와 신사들이 나와 즐겁게 지켜보았다. 각자 엄지 공주에게 선물을 주었는데 최고의 선물은 커다란 은색 파리가 달았던 날개 한 쌍이었다. 그 날개를 등에 단단히 묶자 엄지 공주도 꽃과 꽃 사이를 살랑살랑 돌아다닐 수 있었다. 모두가 즐거워했다. 제비는 이들 위, 자기 둥지에 자리를 잡고는 제일 잘하는 노래를 들려주었다. 그렇지만 마음 깊은 곳에서는 슬픔이 밀려왔다. 엄지 공주를 무척이나 좋아해서 절대 헤어지고 싶지 않았기 때문이다.'\n",
    "\n",
    "\n",
    "prediction(span1)\n",
    "prediction(span2)\n",
    "prediction(span3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
